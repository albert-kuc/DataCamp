{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating data\n",
    "Having learned how to import multiple DataFrames and share information using Indexes, in this chapter you'll learn how to perform database-style operations to combine DataFrames. In particular, you'll learn about appending and concatenating DataFrames while working with a variety of real-world datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Appending & concatenating Series\n",
    "### 1.1 Appending Series with nonunique Indices\n",
    "The Series `bronze` and `silver`, which have been printed in the IPython Shell, represent the 5 countries that won the most bronze and silver Olympic medals respectively between 1896 & 2008. The Indexes of both Series are called `Country` and the values are the corresponding number of medals won.\n",
    "\n",
    "If you were to run the command `combined = bronze.append(silver)`, how many rows would `combined` have? And how many rows would `combined.loc['United States']` return? Find out for yourself by running these commands in the IPython Shell.\n",
    "\n",
    "Possible Answers:\n",
    "* `combined` has 5 rows and `combined.loc['United States']` is empty (0 rows).\n",
    "* `combined` has 10 rows and `combined.loc['United States']` has 2 rows.\n",
    "* `combined` has 6 rows and `combined.loc['United States']` has 1 row.\n",
    "* `combined` has 5 rows and `combined.loc['United States']` has 2 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "United States     1195.0\n",
       "Soviet Union       627.0\n",
       "United Kingdom     591.0\n",
       "France             461.0\n",
       "Italy              394.0\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "silver = pd.read_csv('_datasets/Summer_Olympics/Silver.csv', index_col='Country')['Total'].nlargest(5)\n",
    "silver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "United States     1052.0\n",
       "Soviet Union       584.0\n",
       "United Kingdom     505.0\n",
       "France             475.0\n",
       "Germany            454.0\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze = pd.read_csv('_datasets/Summer_Olympics/Bronze.csv', index_col='Country')['Total'].nlargest(5)\n",
    "bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "United States     1052.0\n",
       "Soviet Union       584.0\n",
       "United Kingdom     505.0\n",
       "France             475.0\n",
       "Germany            454.0\n",
       "United States     1195.0\n",
       "Soviet Union       627.0\n",
       "United Kingdom     591.0\n",
       "France             461.0\n",
       "Italy              394.0\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = bronze.append(silver)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "United States    1052.0\n",
       "United States    1195.0\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.loc['United States']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined Series has 10 rows and `combined.loc['United States']` has two rows, since the index value `'United States'` occurs in both series `bronze` and `silver`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Appending pandas Series\n",
    "In this exercise, you'll load sales data from the months January, February, and March into DataFrames. Then, you'll extract Series with the `'Units'` column from each and append them together with method chaining using `.append()`.\n",
    "\n",
    "To check that the stacking worked, you'll print slices from these Series, and finally, you'll add the result to figure out the total units sold in the first quarter.\n",
    "\n",
    "### Instructions:\n",
    "* Read the files `'sales-jan-2015.csv'`, `'sales-feb-2015.csv'` and `'sales-mar-2015.csv'` into the DataFrames `jan`, `feb`, and `mar` respectively.\n",
    "* Use `parse_dates=True` and `index_col='Date'`.\n",
    "* Extract the `'Units'` column of `jan`, `feb`, and `mar` to create the Series `jan_units`, `feb_units`, and `mar_units` respectively.\n",
    "* Construct the Series `quarter1` by appending `feb_units` to `jan_units` and then appending `mar_units` to the result. Use chained calls to the `.append()` method to do this.\n",
    "* Verify that `quarter1` has the individual Series stacked vertically. To do this:\n",
    "* Print the slice containing rows from `jan 27, 2015` to `feb 2, 2015`.\n",
    "* Print the slice containing rows from `feb 26, 2015` to `mar 7, 2015`.\n",
    "* Compute and print the total number of units sold from the Series `quarter1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-01-27 07:11:55    18\n",
       "2015-02-02 08:33:01     3\n",
       "2015-02-02 20:54:49     9\n",
       "Name: Units, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load 'sales-jan-2015.csv' into a DataFrame: jan\n",
    "jan = pd.read_csv('_datasets/Sales/sales-jan-2015.csv', parse_dates=True, index_col='Date')\n",
    "# Load 'sales-feb-2015.csv' into a DataFrame: feb\n",
    "feb = pd.read_csv('_datasets/Sales/sales-feb-2015.csv', parse_dates=True, index_col='Date')\n",
    "# Load 'sales-mar-2015.csv' into a DataFrame: mar\n",
    "mar = pd.read_csv('_datasets/Sales/sales-mar-2015.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Extract the 'Units' column from jan: jan_units\n",
    "jan_units = jan['Units']\n",
    "# Extract the 'Units' column from feb: feb_units\n",
    "feb_units = feb['Units']\n",
    "# Extract the 'Units' column from mar: mar_units\n",
    "mar_units = mar['Units']\n",
    "\n",
    "# Append feb_units and then mar_units to jan_units: quarter1\n",
    "quarter1 = jan_units.append(feb_units).append(mar_units)\n",
    "\n",
    "# Print the first slice from quarter1\n",
    "quarter1.loc['jan 27, 2015':'feb 2, 2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-02-26 08:57:45     4\n",
       "2015-02-26 08:58:51     1\n",
       "2015-03-06 10:11:45    17\n",
       "2015-03-06 02:03:56    17\n",
       "Name: Units, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the second slice from quarter1\n",
    "quarter1.loc['feb 26, 2015':'mar 7, 2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute & print total sales in quarter1\n",
    "quarter1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Concatenating pandas Series along row axis\n",
    "Having learned how to append Series, you'll now learn how to achieve the same result by concatenating Series instead. You'll continue to work with the sales data you've seen previously. \n",
    "\n",
    "Your job is to use `pd.concat()` with a list of Series to achieve the same result that you would get by chaining calls to `.append()`.\n",
    "\n",
    "You may be wondering about the difference between `pd.concat()` and pandas' `.append()` method. One way to think of the difference is that `.append()` is a specific case of a concatenation, while `pd.concat()` gives you more flexibility, as you'll see in later exercises.\n",
    "\n",
    "### Instructions:\n",
    "* Create an empty list called `units`. This has been done for you.\n",
    "* Use a `for` loop to iterate over `[jan, feb, mar]`:\n",
    "    * In each iteration of the loop, append the `'Units'` column of each DataFrame to `units`.\n",
    "* Concatenate the Series contained in the list `units` into a longer Series called `quarter1` using `pd.concat()`.\n",
    "    * Specify the keyword argument `axis='rows'` to stack the Series vertically.\n",
    "* Verify that `quarter1` has the individual Series stacked vertically by printing slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-01-27 07:11:55    18\n",
       "2015-02-02 08:33:01     3\n",
       "2015-02-02 20:54:49     9\n",
       "Name: Units, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty list: units\n",
    "units = []\n",
    "\n",
    "# Build the list of Series\n",
    "for month in [jan, feb, mar]:\n",
    "    units.append(month['Units'])\n",
    "\n",
    "# Concatenate the list: quarter1\n",
    "quarter1 = pd.concat(units, axis='rows')\n",
    "\n",
    "# Print slices from quarter1\n",
    "quarter1.loc['jan 27, 2015':'feb 2, 2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-02-26 08:57:45     4\n",
       "2015-02-26 08:58:51     1\n",
       "2015-03-06 10:11:45    17\n",
       "2015-03-06 02:03:56    17\n",
       "Name: Units, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarter1.loc['feb 26, 2015':'mar 7, 2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
