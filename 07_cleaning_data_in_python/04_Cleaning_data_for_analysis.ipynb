{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data for analysis\n",
    "Here, you'll dive into some of the grittier aspects of data cleaning. You'll learn about string manipulation and pattern matching to deal with unstructured data, and then explore techniques to deal with missing or duplicate data. You'll also learn the valuable skill of programmatically checking your data for consistency, which will give you confidence that your code is running correctly and that the results of your analysis are reliable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data types\n",
    "## 1.1 Converting data types\n",
    "In this exercise, you'll see how ensuring all categorical variables in a DataFrame are of type `category` reduces memory usage.\n",
    "\n",
    "The [tips dataset](https://github.com/mwaskom/seaborn-data/blob/master/tips.csv) has been loaded into a DataFrame called `tips`. This data contains information about how much a customer tipped, whether the customer was male or female, a smoker or not, etc.\n",
    "\n",
    "Look at the output of `tips.info()` in the IPython Shell. You'll note that two columns that should be categorical - `sex` and `smoker` - are instead of type `object`, which is pandas' way of storing arbitrary strings. Your job is to convert these two columns to type `category` and note the reduced memory usage.\n",
    "\n",
    "### Instructions:\n",
    "* Convert the `sex` column of the `tips` DataFrame to type `'category'` using the `.astype()` method.\n",
    "* Convert the `smoker` column of the `tips` DataFrame.\n",
    "* Print the memory usage of `tips` after converting the data types of the columns. Use the `.info()` method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      "total_bill    244 non-null float64\n",
      "tip           244 non-null float64\n",
      "sex           244 non-null object\n",
      "smoker        244 non-null object\n",
      "day           244 non-null object\n",
      "time          244 non-null object\n",
      "size          244 non-null int64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 9.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tips = pd.read_csv('_datasets/tips.csv')\n",
    "\n",
    "tips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      "total_bill    244 non-null float64\n",
      "tip           244 non-null float64\n",
      "sex           244 non-null category\n",
      "smoker        244 non-null category\n",
      "day           244 non-null object\n",
      "time          244 non-null object\n",
      "size          244 non-null int64\n",
      "dtypes: category(2), float64(2), int64(1), object(2)\n",
      "memory usage: 8.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Convert the sex column to type 'category'\n",
    "tips.sex = tips.sex.astype('category')\n",
    "\n",
    "# Convert the smoker column to type 'category'\n",
    "tips.smoker = tips.smoker.astype('category')\n",
    "\n",
    "# Print the info of tips\n",
    "tips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By converting `sex` and `smoker` to categorical variables, the memory usage of the DataFrame went down. This may seem like a small difference here, but when you're dealing with large datasets, the reduction in memory usage can be very significant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Working with numeric data\n",
    "If you expect the data type of a column to be numeric (`int` or `float`), but instead it is of type object, this typically means that there is a non `numeric` value in the column, which also signifies bad data.\n",
    "\n",
    "You can use the `pd.to_numeric()` function to convert a column into a numeric data type. If the function raises an error, you can be sure that there is a bad value within the column. You can either use the techniques you learned in Chapter 1 to do some exploratory data analysis and find the bad value, or you can choose to ignore or `coerce` the value into a missing value, `NaN`.\n",
    "\n",
    "A modified version of the tips dataset has been pre-loaded into a DataFrame called `tips`. For instructional purposes, it has been pre-processed to introduce some 'bad' data for you to clean. Use the `.info()` method to explore this. You'll note that the `total_bill` and `tip` columns, which should be numeric, are instead of type `object`. Your job is to fix this.\n",
    "\n",
    "### Instructions:\n",
    "* Use `pd.to_numeric()` to convert the `'total_bill'` column of `tips` to a numeric data type. Coerce the errors to `NaN` by specifying the keyword argument `errors='coerce'`.\n",
    "* Convert the `'tip'` column of `'tips'` to a numeric data type exactly as you did for the `'total_bill'` column.\n",
    "* Print the `info` of `tips` to confirm that the data types of `'total_bill'` and `'tips'` are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      "total_bill    244 non-null float64\n",
      "tip           244 non-null float64\n",
      "sex           244 non-null category\n",
      "smoker        244 non-null category\n",
      "day           244 non-null object\n",
      "time          244 non-null object\n",
      "size          244 non-null int64\n",
      "dtypes: category(2), float64(2), int64(1), object(2)\n",
      "memory usage: 8.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Convert 'total_bill' to a numeric dtype\n",
    "tips['total_bill'] = pd.to_numeric(tips['total_bill'], errors='coerce')\n",
    "\n",
    "# Convert 'tip' to a numeric dtype\n",
    "tips['tip'] = pd.to_numeric(tips['tip'], errors='coerce')\n",
    "\n",
    "# Print the info of tips\n",
    "tips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'total_bill'` and `'tip'` columns in this DataFrame are stored as `object` types because the string `'missing'` is used in these columns to encode missing values. By coercing the values into a numeric type, they become proper `NaN` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using regular expressions to clean strings\n",
    "## 2.1 String parsing with regular expressions\n",
    "In the video, Dan introduced you to the basics of regular expressions, which are powerful ways of defining patterns to match strings. This exercise will get you started with writing them.\n",
    "\n",
    "When working with data, it is sometimes necessary to write a regular expression to look for properly entered values. Phone numbers in a dataset is a common field that needs to be checked for validity. Your job in this exercise is to define a regular expression to match US phone numbers that fit the pattern of `xxx-xxx-xxxx`.\n",
    "\n",
    "The [regular expression module](https://docs.python.org/3/library/re.html) in python is `re`. When performing pattern matching on data, since the pattern will be used for a match across multiple rows, it's better to compile the pattern first using `re.compile()`, and then use the compiled pattern to match values.\n",
    "\n",
    "### Instructions:\n",
    "* Import `re`.\n",
    "* Compile a pattern that matches a phone number of the format `xxx-xxx-xxxx`.\n",
    "    * Use `\\d{x}` to match `x` digits. Here you'll need to use it three times: twice to match `3` digits, and once to match `4` digits.\n",
    "    * Place the regular expression inside `re.compile()`.\n",
    "* Using the `.match()` method on `prog`, check whether the pattern matches the string `'123-456-7890'`.\n",
    "* Using the same approach, now check whether the pattern matches the string `'1123-456-7890'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Compile the pattern: prog\n",
    "prog = re.compile('\\d{3}-\\d{3}-\\d{4}')\n",
    "\n",
    "# See if the pattern matches\n",
    "result = prog.match('123-456-7890')\n",
    "bool(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if the pattern matches\n",
    "result2 = prog.match('1123-456-7890')\n",
    "bool(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions can seem challenging at first, but with practice, you'll get better and better at writing them! Here, as expected, the pattern matches the first string, but not the second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Extracting numerical values from strings\n",
    "Extracting numbers from strings is a common task, particularly when working with unstructured data or log files.\n",
    "\n",
    "Say you have the following string: `'the recipe calls for 6 strawberries and 2 bananas'`.\n",
    "\n",
    "It would be useful to extract the `6` and the `2` from this string to be saved for later use when comparing strawberry to banana ratios.\n",
    "\n",
    "When using a regular expression to extract multiple numbers (or multiple pattern matches, to be exact), you can use the `re.findall()` function. Dan did not discuss this in the video, but it is straightforward to use: You pass in a pattern and a string to `re.findall()`, and it will return a list of the matches.\n",
    "\n",
    "### Instructions:\n",
    "* Import `re`.\n",
    "* Write a pattern that will find all the numbers in the following string: `'the recipe calls for 10 strawberries and 1 banana'`. To do this:\n",
    "    * Use the `re.findall()` function and pass it two arguments: the pattern, followed by the string.\n",
    "    * `\\d` is the pattern required to find digits. This should be followed with a `+` so that the previous element is matched one or more times. This ensures that `10` is viewed as one number and not as `1` and `0`.\n",
    "* Print the matches to confirm that your regular expression found the values `10` and `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Find the numeric values: matches\n",
    "matches = re.findall('\\d+', 'the recipe calls for 10 strawberries and 1 banana')\n",
    "\n",
    "# Print the matches\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression successfully extracted the numeric values `10` and `1` from the string!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Pattern matching\n",
    "In this exercise, you'll continue practicing your regular expression skills. For each provided string, your job is to write the appropriate pattern to match it.\n",
    "\n",
    "### Instructions:\n",
    "* Write patterns to match:\n",
    "    * A telephone number of the format `xxx-xxx-xxxx`. You already did this in a previous exercise.\n",
    "    * A string of the format: A dollar sign, an arbitrary number of digits, a decimal point, 2 digits.\n",
    "        * Use `\\$` to match the dollar sign, `\\d*` to match an arbitrary number of digits, `\\.` to match the decimal point, and `\\d{x}` to match `x` number of digits.\n",
    "    * A capital letter, followed by an arbitrary number of alphanumeric characters.\n",
    "        * Use `[A-Z]` to match any capital letter followed by `\\w*` to match an arbitrary number of alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the first pattern\n",
    "pattern1 = bool(re.match(pattern='\\d{3}-\\d{3}-\\d{4}', string='123-456-7890'))\n",
    "pattern1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the second pattern\n",
    "pattern2 = bool(re.match(pattern='\\$\\d*.\\d{2}', string='$123.45'))\n",
    "pattern2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the third pattern\n",
    "pattern3 = bool(re.match(pattern='[A-Z]\\w*', string='Australia'))\n",
    "pattern3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using functions to clean data\n",
    "## 3.1 Custom functions to clean data\n",
    "The tips dataset has been pre-loaded into a DataFrame called `tips`. It has a `'sex'` column that contains the values `'Male'` or `'Female'`. Your job is to write a function that will recode `'Female'` to `0`, `'Male'` to `1`, and return `np.nan` for all entries of `'sex'` that are neither `'Female'` nor `'Male'`.\n",
    "\n",
    "Recoding variables like this is a common data cleaning task. Functions provide a mechanism for you to abstract away complex bits of code as well as reuse code. This makes your code more readable and less error prone.\n",
    "\n",
    "As Dan showed you in the videos, you can use the `.apply()` method to _apply_ a function across entire rows or columns of DataFrames. However, note that each column of a DataFrame is a pandas Series. Functions can also be applied across Series. Here, you will apply your function over the `'sex'` column.\n",
    "\n",
    "### Instructions:\n",
    "* Define a function named `recode_gender()` that has one parameter: `gender`.\n",
    "    * If `gender` equals `'Male'`, return `1`.\n",
    "    * Else, if `gender` equals `'Female'`, return `0`.\n",
    "    * If `gender` does not equal `'Male'` or `'Female'`, return `np.nan`. NumPy has been pre-imported.\n",
    "* Apply your `recode_gender()` function over `tips.sex` using the `.apply()` method to create a new column: `'recode'`. Note that when passing in a function inside the `.apply()` method, you don't need to specify the parentheses after the function name.\n",
    "* Hit 'Submit Answer' and take note of the new `'gender_recode'` column in the `tips` DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tips = pd.read_csv('_datasets/tips_nan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>sex_recode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size  sex_recode\n",
       "0       16.99  1.01  Female     No  Sun  Dinner   2.0         0.0\n",
       "1       10.34  1.66     NaN     No  Sun  Dinner   3.0         NaN\n",
       "2       21.01   NaN    Male     No  Sun  Dinner   3.0         1.0\n",
       "3       23.68  3.31    Male    NaN  Sun  Dinner   2.0         1.0\n",
       "4         NaN  3.61  Female     No  Sun  Dinner   4.0         0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define recode_sex()\n",
    "def recode_sex(sex_value):\n",
    "\n",
    "    # Return 1 if sex_value is 'Male'\n",
    "    if sex_value == 'Male':\n",
    "        return 1\n",
    "    \n",
    "    # Return 0 if sex_value is 'Female'    \n",
    "    elif sex_value == 'Female':\n",
    "        return 0\n",
    "    \n",
    "    # Return np.nan    \n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the sex column\n",
    "tips['sex_recode'] = tips.sex.apply(recode_sex)\n",
    "\n",
    "# Print the first five rows of tips\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple recodes, you can also use the `replace` method. You can also convert the column into a categorical type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Lambda functions\n",
    "You'll now be introduced to a powerful Python feature that will help you clean your data more effectively: lambda functions. Instead of using the `def` syntax that you used in the previous exercise, lambda functions let you make simple, one-line functions.\n",
    "\n",
    "For example, here's a function that squares a variable used in an `.apply()` method:\n",
    "```\n",
    "def my_square(x):\n",
    "    return x ** 2\n",
    "\n",
    "df.apply(my_square)\n",
    "```\n",
    "The equivalent code using a lambda function is:\n",
    "```\n",
    "df.apply(lambda x: x ** 2)\n",
    "```\n",
    "The lambda function takes one parameter - the variable `x`. The function itself just squares `x` and returns the result, which is whatever the one line of code evaluates to. In this way, lambda functions can make your code concise and Pythonic.\n",
    "\n",
    "The tips dataset has been pre-loaded into a DataFrame called `tips`. Your job is to clean its `'total_dollar'` column by removing the dollar sign. You'll do this using two different methods: With the `.replace()` method, and with regular expressions. The regular expression module `re` has been pre-imported.\n",
    "\n",
    "### Instructions:\n",
    "* Use the `.replace()` method inside a lambda function to remove the dollar sign from the `'total_dollar'` column of `tips`.\n",
    "    * You need to specify two arguments to the `.replace()` method: The string to be replaced (`'$'`), and the string to replace it by (`''`).\n",
    "    * Apply the lambda function over the `'total_dollar'` column of `tips`.\n",
    "* Use a regular expression to remove the dollar sign from the `'total_dollar'` column of `tips`.\n",
    "    * The pattern has been provided for you: It is the first argument of the `re.findall()` function.\n",
    "    * Complete the rest of the lambda function and apply it over the `'total_dollar'` column of `tips`. Notice that because `re.findall()` returns a list, you have to slice it in order to access the actual value.\n",
    "* Hit 'Submit Answer' to verify that you have removed the dollar sign from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size total_dollar\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2       $16.99\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3       $10.34\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3       $21.01\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2       $23.68\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4       $24.59\n"
     ]
    }
   ],
   "source": [
    "tips = pd.read_csv('_datasets/tips.csv')\n",
    "tips['total_dollar'] = '$' + tips['total_bill'].astype(str)\n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size total_dollar  \\\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2       $16.99   \n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3       $10.34   \n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3       $21.01   \n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2       $23.68   \n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4       $24.59   \n",
      "\n",
      "  total_dollar_replace total_dollar_re  \n",
      "0                16.99           16.99  \n",
      "1                10.34           10.34  \n",
      "2                21.01           21.01  \n",
      "3                23.68           23.68  \n",
      "4                24.59           24.59  \n"
     ]
    }
   ],
   "source": [
    "# Write the lambda function using replace\n",
    "tips['total_dollar_replace'] = tips.total_dollar.apply(lambda x: x.replace('$', ''))\n",
    "\n",
    "# Write the lambda function using regular expressions\n",
    "tips['total_dollar_re'] = tips.total_dollar.apply(lambda x: re.findall('\\d+\\.\\d+', x)[0])\n",
    "\n",
    "# Print the head of tips\n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `'total_dollar_re'` and `'total_dollar_replace'` columns are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Duplicate and missing data\n",
    "## 4.1 Dropping duplicate data\n",
    "Duplicate data causes a variety of problems. From the point of view of performance, they use up unnecessary amounts of memory and cause unneeded calculations to be performed when processing data. In addition, they can also bias any analysis results.\n",
    "\n",
    "A dataset consisting of the performance of songs on the Billboard charts has been pre-loaded into a DataFrame called `billboard`. Check out its columns in the IPython Shell. Your job in this exercise is to subset this DataFrame and then drop all duplicate rows.\n",
    "\n",
    "### Instructions:\n",
    "* Create a new DataFrame called `tracks` that contains the following columns from `billboard`: `'year'`, `'artist'`, `'track'`, and `'time'`.\n",
    "* Print the `info` of `tracks`. This has been done for you.\n",
    "* Drop duplicate rows from `tracks` using the `.drop_duplicates()` method. Save the result to `tracks_no_duplicates`.\n",
    "* Print the `info` of `tracks_no_duplicates`. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>date.entered</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2Ge+her</td>\n",
       "      <td>The Hardest Part Of ...</td>\n",
       "      <td>3:15</td>\n",
       "      <td>2000-09-02</td>\n",
       "      <td>wk1</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>2 Pac</td>\n",
       "      <td>Baby Don't Cry</td>\n",
       "      <td>4:22</td>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>wk1</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>Kryptonite</td>\n",
       "      <td>3:53</td>\n",
       "      <td>2000-04-08</td>\n",
       "      <td>wk1</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>Loser</td>\n",
       "      <td>4:24</td>\n",
       "      <td>2000-10-21</td>\n",
       "      <td>wk1</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>504 Boyz</td>\n",
       "      <td>Wobble Wobble</td>\n",
       "      <td>3:35</td>\n",
       "      <td>2000-04-15</td>\n",
       "      <td>wk1</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        artist                    track  time date.entered variable  \\\n",
       "0  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02      wk1   \n",
       "1  2000         2 Pac           Baby Don't Cry  4:22   2000-02-26      wk1   \n",
       "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08      wk1   \n",
       "3  2000  3 Doors Down                    Loser  4:24   2000-10-21      wk1   \n",
       "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15      wk1   \n",
       "\n",
       "   value  \n",
       "0   91.0  \n",
       "1   87.0  \n",
       "2   81.0  \n",
       "3   76.0  \n",
       "4   57.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard = pd.read_csv('_datasets/billboard.csv')\n",
    "# Reshape billboard file using melt to convert wk data column data into rows\n",
    "billboard = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'])\n",
    "billboard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24092 entries, 0 to 24091\n",
      "Data columns (total 4 columns):\n",
      "year      24092 non-null int64\n",
      "artist    24092 non-null object\n",
      "track     24092 non-null object\n",
      "time      24092 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 470.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Create the new DataFrame: tracks\n",
    "tracks = billboard[['year', 'artist', 'track', 'time']]\n",
    "\n",
    "# Print info of tracks\n",
    "tracks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 317 entries, 0 to 316\n",
      "Data columns (total 4 columns):\n",
      "year      317 non-null int64\n",
      "artist    317 non-null object\n",
      "track     317 non-null object\n",
      "time      317 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop the duplicates: tracks_no_duplicates\n",
    "tracks_no_duplicates = tracks.drop_duplicates()\n",
    "\n",
    "# Print info of tracks\n",
    "tracks_no_duplicates.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping duplicates, the DataFrame has gone from having `24092` entries to only `317`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Filling missing data\n",
    "Here, you'll return to the `airquality` dataset from Chapter 2. It has been pre-loaded into the DataFrame `airquality`, and it has missing values for you to practice filling in. Explore `airquality` in the IPython Shell to checkout which columns have missing values.\n",
    "\n",
    "It's rare to have a (real-world) dataset without any missing values, and it's important to deal with them because certain calculations cannot handle missing values while some calculations will, by default, skip over any missing values.\n",
    "\n",
    "Also, understanding how much missing data you have, and thinking about where it comes from is crucial to making unbiased interpretations of data.\n",
    "\n",
    "### Instructions:\n",
    "* Calculate the mean of the `Ozone` column of `airquality` using the `.mean()` method on `airquality.Ozone`.\n",
    "* Use the `.fillna()` method to replace all the missing values in the `Ozone` column of `airquality` with the mean, `oz_mean`.\n",
    "* Hit 'Submit Answer' to see the result of filling in the missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      "Ozone      116 non-null float64\n",
      "Solar.R    146 non-null float64\n",
      "Wind       153 non-null float64\n",
      "Temp       153 non-null int64\n",
      "Month      153 non-null int64\n",
      "Day        153 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.2 KB\n"
     ]
    }
   ],
   "source": [
    "airquality = pd.read_csv('_datasets/airquality.csv')\n",
    "# Print the info of airquality\n",
    "airquality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      "Ozone      153 non-null float64\n",
      "Solar.R    146 non-null float64\n",
      "Wind       153 non-null float64\n",
      "Temp       153 non-null int64\n",
      "Month      153 non-null int64\n",
      "Day        153 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of the Ozone column: oz_mean\n",
    "oz_mean = airquality.Ozone.mean()\n",
    "\n",
    "# Replace all the missing values in the Ozone column with the mean\n",
    "airquality['Ozone'] = airquality['Ozone'].fillna(oz_mean)\n",
    "\n",
    "# Print the info of airquality\n",
    "airquality.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no longer any missing values in the `Ozone` column of this DataFrame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing with asserts\n",
    "## 5.1 Testing your data with asserts\n",
    "Here, you'll practice writing assert statements using the Ebola dataset from previous chapters to programmatically check for missing values and to confirm that all values are positive. The dataset has been pre-loaded into a DataFrame called `ebola`.\n",
    "\n",
    "In the video, you saw Dan use the `.all()` method together with the `.notnull()` DataFrame method to check for missing values in a column. The `.all()` method returns `True` if all values are `True`. When used on a DataFrame, it returns a Series of Booleans - one for each column in the DataFrame. So if you are using it on a DataFrame, like in this exercise, you need to chain another `.all()` method so that you return only one `True` or `False` value. When using these within an assert statement, nothing will be returned if the assert statement is true: This is how you can confirm that the data you are checking are valid.\n",
    "\n",
    "Note: You can use `pd.notnull(df)` as an alternative to `df.notnull()`.\n",
    "\n",
    "### Instructions:\n",
    "* Write an assert statement to confirm that there are no missing values in `ebola`.\n",
    "    * Use the `pd.notnull()` function on `ebola` (or the `.notnull()` method of `ebola`) and chain two `.all()` methods (that is, `.all().all()`). The first `.all()` method will return a `True` or `False` for each column, while the second `.all()` method will return a single `True` or `False`.\n",
    "* Write an assert statement to confirm that all values in `ebola` are greater than or equal to `0`.\n",
    "    * Chain two `all()` methods to the Boolean condition (`ebola >= 0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122 entries, 0 to 121\n",
      "Data columns (total 18 columns):\n",
      "Date                   122 non-null object\n",
      "Day                    122 non-null int64\n",
      "Cases_Guinea           93 non-null float64\n",
      "Cases_Liberia          83 non-null float64\n",
      "Cases_SierraLeone      87 non-null float64\n",
      "Cases_Nigeria          38 non-null float64\n",
      "Cases_Senegal          25 non-null float64\n",
      "Cases_UnitedStates     18 non-null float64\n",
      "Cases_Spain            16 non-null float64\n",
      "Cases_Mali             12 non-null float64\n",
      "Deaths_Guinea          92 non-null float64\n",
      "Deaths_Liberia         81 non-null float64\n",
      "Deaths_SierraLeone     87 non-null float64\n",
      "Deaths_Nigeria         38 non-null float64\n",
      "Deaths_Senegal         22 non-null float64\n",
      "Deaths_UnitedStates    18 non-null float64\n",
      "Deaths_Spain           16 non-null float64\n",
      "Deaths_Mali            12 non-null float64\n",
      "dtypes: float64(16), int64(1), object(1)\n",
      "memory usage: 16.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ebola = pd.read_csv('_datasets/ebola.csv')\n",
    "ebola.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122 entries, 0 to 121\n",
      "Data columns (total 18 columns):\n",
      "Date                   122 non-null object\n",
      "Day                    122 non-null int64\n",
      "Cases_Guinea           122 non-null float64\n",
      "Cases_Liberia          122 non-null float64\n",
      "Cases_SierraLeone      122 non-null float64\n",
      "Cases_Nigeria          122 non-null float64\n",
      "Cases_Senegal          122 non-null float64\n",
      "Cases_UnitedStates     122 non-null float64\n",
      "Cases_Spain            122 non-null float64\n",
      "Cases_Mali             122 non-null float64\n",
      "Deaths_Guinea          122 non-null float64\n",
      "Deaths_Liberia         122 non-null float64\n",
      "Deaths_SierraLeone     122 non-null float64\n",
      "Deaths_Nigeria         122 non-null float64\n",
      "Deaths_Senegal         122 non-null float64\n",
      "Deaths_UnitedStates    122 non-null float64\n",
      "Deaths_Spain           122 non-null float64\n",
      "Deaths_Mali            122 non-null float64\n",
      "dtypes: float64(16), int64(1), object(1)\n",
      "memory usage: 16.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values with 0\n",
    "ebola = ebola.fillna(0)\n",
    "ebola.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that there are no missing values\n",
    "assert ebola.notnull().all().all()\n",
    "\n",
    "# Assert that all values are >= 0\n",
    "assert (ebola>=0).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the assert statements did not throw any errors, you can be sure that there are no missing values in the data and that all values are `>=` 0!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
