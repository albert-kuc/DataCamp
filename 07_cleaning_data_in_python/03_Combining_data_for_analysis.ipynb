{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data for analysis\n",
    "The ability to transform and combine your data is a crucial skill in data science, because your data may not always come in one monolithic file or table for you to load. A large dataset may be broken into separate datasets to facilitate easier storage and sharing. Or if you are dealing with time series data, for example, you may have a new dataset for each day. No matter the reason, it is important to be able to combine datasets so you can either clean a single dataset, or clean each dataset separately and then combine them later so you can run your analysis on a single dataset. In this chapter, you'll learn all about combining data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Concatenating data\n",
    "## 1.1 Combining rows of data\n",
    "The dataset you'll be working with here relates to [NYC Uber data](http://data.beta.nyc/dataset/uber-trip-data-foiled-apr-sep-2014). The original dataset has all the originating Uber pickup locations by time and latitude and longitude. For didactic purposes, you'll be working with a very small portion of the actual data.\n",
    "\n",
    "Three DataFrames have been pre-loaded: `uber1`, which contains data for April 2014, `uber2`, which contains data for May 2014, and `uber3`, which contains data for June 2014. Your job in this exercise is to concatenate these DataFrames together such that the resulting DataFrame has the data for all three months.\n",
    "\n",
    "Begin by exploring the structure of these three DataFrames in the IPython Shell using methods such as `.head()`.\n",
    "\n",
    "### Instructions:\n",
    "* Concatenate `uber1`, `uber2`, and `uber3` together using `pd.concat()`. You'll have to pass the DataFrames in as a list.\n",
    "* Print the shape and then the head of the concatenated DataFrame, `row_concat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "uber1 = pd.read_csv('_datasets/uber-raw-data-2014_04.csv')\n",
    "uber2 = pd.read_csv('_datasets/uber-raw-data-2014_05.csv')\n",
    "uber3 = pd.read_csv('_datasets/uber-raw-data-2014_06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 5)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate uber1, uber2, and uber3: row_concat\n",
    "row_concat = pd.concat([uber1,uber2, uber3])\n",
    "\n",
    "# Print the shape of row_concat\n",
    "print(row_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4/1/2014 0:11:00</td>\n",
       "      <td>40.7690</td>\n",
       "      <td>-73.9549</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4/1/2014 0:17:00</td>\n",
       "      <td>40.7267</td>\n",
       "      <td>-74.0345</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4/1/2014 0:21:00</td>\n",
       "      <td>40.7316</td>\n",
       "      <td>-73.9873</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4/1/2014 0:28:00</td>\n",
       "      <td>40.7588</td>\n",
       "      <td>-73.9776</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4/1/2014 0:33:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9722</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Date/Time      Lat      Lon    Base\n",
       "0           0  4/1/2014 0:11:00  40.7690 -73.9549  B02512\n",
       "1           1  4/1/2014 0:17:00  40.7267 -74.0345  B02512\n",
       "2           2  4/1/2014 0:21:00  40.7316 -73.9873  B02512\n",
       "3           3  4/1/2014 0:28:00  40.7588 -73.9776  B02512\n",
       "4           4  4/1/2014 0:33:00  40.7594 -73.9722  B02512"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of row_concat\n",
    "row_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully concatenated the three `uber` DataFrames! Notice that the head of `row_concat` is the same as the head of `uber1`, while the tail of `row_concat` is the same as the tail of `uber3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Combining columns of data\n",
    "Think of column-wise concatenation of data as stitching data together from the sides instead of the top and bottom. To perform this action, you use the same `pd.concat()` function, but this time with the keyword argument `axis=1`. The default, `axis=0`, is for a row-wise concatenation.\n",
    "\n",
    "You'll return to the [Ebola dataset](https://data.humdata.org/dataset/ebola-cases-2014) you worked with briefly in the last chapter. It has been pre-loaded into a DataFrame called `ebola_melt`. In this DataFrame, the status and country of a patient is contained in a single column. This column has been parsed into a new DataFrame, `status_country`, where there are separate columns for status and country.\n",
    "\n",
    "Explore the `ebola_melt` and `status_country` DataFrames in the IPython Shell. Your job is to concatenate them column-wise in order to obtain a final, clean DataFrame.\n",
    "\n",
    "### Instructions:\n",
    "* Concatenate `ebola_melt` and `status_country` column-wise into a single DataFrame called `ebola_tidy`. Be sure to specify `axis=1` and to pass the two DataFrames in as a list.\n",
    "* Print the shape and then the head of the concatenated DataFrame, `ebola_tidy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola = pd.read_csv('_datasets/ebola.csv')\n",
    "\n",
    "# melt the ebola data: ebola_melt\n",
    "ebola_melt = pd.melt(ebola, id_vars=['Date', 'Day'], var_name='status_country', value_name='counts')\n",
    "\n",
    "status_country = ebola_melt.status_country.str.split('_', expand=True)\n",
    "status_country.columns = ['status', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>status_country</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>288</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>287</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>286</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>284</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2730.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day status_country  counts\n",
       "0    1/5/2015  289   Cases_Guinea  2776.0\n",
       "1    1/4/2015  288   Cases_Guinea  2775.0\n",
       "2    1/3/2015  287   Cases_Guinea  2769.0\n",
       "3    1/2/2015  286   Cases_Guinea     NaN\n",
       "4  12/31/2014  284   Cases_Guinea  2730.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebola_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status country\n",
       "0  Cases  Guinea\n",
       "1  Cases  Guinea\n",
       "2  Cases  Guinea\n",
       "3  Cases  Guinea\n",
       "4  Cases  Guinea"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1952, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate ebola_melt and status_country column-wise: ebola_tidy\n",
    "ebola_tidy = pd.concat([ebola_melt, status_country], axis=1)\n",
    "\n",
    "# Print the shape of ebola_tidy\n",
    "ebola_tidy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>status_country</th>\n",
       "      <th>counts</th>\n",
       "      <th>status</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>288</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2775.0</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>287</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>286</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>284</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day status_country  counts status country\n",
       "0    1/5/2015  289   Cases_Guinea  2776.0  Cases  Guinea\n",
       "1    1/4/2015  288   Cases_Guinea  2775.0  Cases  Guinea\n",
       "2    1/3/2015  287   Cases_Guinea  2769.0  Cases  Guinea\n",
       "3    1/2/2015  286   Cases_Guinea     NaN  Cases  Guinea\n",
       "4  12/31/2014  284   Cases_Guinea  2730.0  Cases  Guinea"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of ebola_tidy\n",
    "ebola_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concatenated DataFrame has 6 columns, as it should. Notice how the `status` and `country` columns have been concatenated column-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Finding and concatenating data\n",
    "## 2.1 Finding files that match a pattern\n",
    "You're now going to practice using the `glob` module to find all csv files in the workspace. In the next exercise, you'll programmatically load them into DataFrames.\n",
    "\n",
    "As Dan showed you in the video, the `glob` module has a function called `glob` that takes a pattern and returns a list of the files in the working directory that match that pattern.\n",
    "\n",
    "For example, if you know the pattern is `part_` `single digit number` `.csv`, you can write the pattern as `'part_?.csv'` (which would match `part_1.csv`, `part_2.csv`, `part_3.csv`, etc.)\n",
    "\n",
    "Similarly, you can find all `.csv` files with `'*.csv'`, or all parts with `'part_*'`. The `?` wildcard represents any 1 character, and the `*` wildcard represents any number of characters.\n",
    "\n",
    "### Instructions:\n",
    "* Import the `glob` module along with `pandas` (as its usual alias `pd`).\n",
    "* Write a pattern to match all `.csv` files.\n",
    "* Save all files that match the pattern using the `glob()` function within the `glob` module. That is, by using `glob.glob()`.\n",
    "* Print the list of file names. This has been done for you.\n",
    "* Read the second file in `csv_files` (i.e., index `1`) into a DataFrame called `csv2`.\n",
    "* Hit 'Submit Answer' to print the head of `csv2`. Does it look familiar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_datasets\\\\uber-raw-data-2014_04.csv',\n",
       " '_datasets\\\\uber-raw-data-2014_05.csv',\n",
       " '_datasets\\\\uber-raw-data-2014_06.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Write the pattern: pattern\n",
    "pattern = '_datasets/uber-raw-data-2014_??.csv'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "csv_files = glob.glob(pattern)\n",
    "\n",
    "# Print the file names\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5/1/2014 0:02:00</td>\n",
       "      <td>40.7521</td>\n",
       "      <td>-73.9914</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5/1/2014 0:06:00</td>\n",
       "      <td>40.6965</td>\n",
       "      <td>-73.9715</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5/1/2014 0:15:00</td>\n",
       "      <td>40.7464</td>\n",
       "      <td>-73.9838</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7463</td>\n",
       "      <td>-74.0011</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9734</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Date/Time      Lat      Lon    Base\n",
       "0           0  5/1/2014 0:02:00  40.7521 -73.9914  B02512\n",
       "1           1  5/1/2014 0:06:00  40.6965 -73.9715  B02512\n",
       "2           2  5/1/2014 0:15:00  40.7464 -73.9838  B02512\n",
       "3           3  5/1/2014 0:17:00  40.7463 -74.0011  B02512\n",
       "4           4  5/1/2014 0:17:00  40.7594 -73.9734  B02512"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the second file into a DataFrame: csv2\n",
    "csv2 = pd.read_csv(csv_files[1])\n",
    "\n",
    "# Print the head of csv2\n",
    "csv2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to iterate through this list of filenames, load it into a DataFrame, and add it to a list of DataFrames you can then concatenate together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Iterating and concatenating all matches\n",
    "Now that you have a list of filenames to load, you can load all the files into a list of DataFrames that can then be concatenated.\n",
    "\n",
    "You'll start with an empty list called `frames`. Your job is to use a `for` loop to:\n",
    "\n",
    "1. iterate through each of the filenames\n",
    "2. read each filename into a DataFrame, and then\n",
    "3. append it to the frames list.\n",
    "\n",
    "You can then concatenate this list of DataFrames using pd.concat(). Go for it!\n",
    "\n",
    "### Instructions:\n",
    "* Write a `for` loop to iterate through `csv_files`:\n",
    "    * In each iteration of the loop, read `csv` into a DataFrame called `df`.\n",
    "    * After creating `df`, append it to the list `frames` using the `.append()` method.\n",
    "* Concatenate `frames` into a single DataFrame called `uber`.\n",
    "* Hit 'Submit Answer' to see the head and shape of the concatenated DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    Unnamed: 0         Date/Time      Lat      Lon    Base\n",
       " 0            0  4/1/2014 0:11:00  40.7690 -73.9549  B02512\n",
       " 1            1  4/1/2014 0:17:00  40.7267 -74.0345  B02512\n",
       " 2            2  4/1/2014 0:21:00  40.7316 -73.9873  B02512\n",
       " 3            3  4/1/2014 0:28:00  40.7588 -73.9776  B02512\n",
       " 4            4  4/1/2014 0:33:00  40.7594 -73.9722  B02512\n",
       " 5            5  4/1/2014 0:33:00  40.7383 -74.0403  B02512\n",
       " 6            6  4/1/2014 0:39:00  40.7223 -73.9887  B02512\n",
       " 7            7  4/1/2014 0:45:00  40.7620 -73.9790  B02512\n",
       " 8            8  4/1/2014 0:55:00  40.7524 -73.9960  B02512\n",
       " 9            9  4/1/2014 1:01:00  40.7575 -73.9846  B02512\n",
       " 10          10  4/1/2014 1:19:00  40.7256 -73.9869  B02512\n",
       " 11          11  4/1/2014 1:48:00  40.7591 -73.9684  B02512\n",
       " 12          12  4/1/2014 1:49:00  40.7271 -73.9803  B02512\n",
       " 13          13  4/1/2014 2:11:00  40.6463 -73.7896  B02512\n",
       " 14          14  4/1/2014 2:25:00  40.7564 -73.9167  B02512\n",
       " 15          15  4/1/2014 2:31:00  40.7666 -73.9531  B02512\n",
       " 16          16  4/1/2014 2:43:00  40.7580 -73.9761  B02512\n",
       " 17          17  4/1/2014 3:22:00  40.7238 -73.9821  B02512\n",
       " 18          18  4/1/2014 3:35:00  40.7531 -74.0039  B02512\n",
       " 19          19  4/1/2014 3:35:00  40.7389 -74.0393  B02512\n",
       " 20          20  4/1/2014 3:41:00  40.7619 -73.9715  B02512\n",
       " 21          21  4/1/2014 4:11:00  40.7530 -74.0042  B02512\n",
       " 22          22  4/1/2014 4:15:00  40.6561 -73.9531  B02512\n",
       " 23          23  4/1/2014 4:19:00  40.7250 -73.9844  B02512\n",
       " 24          24  4/1/2014 4:20:00  40.6950 -74.1783  B02512\n",
       " 25          25  4/1/2014 4:26:00  40.9859 -74.1578  B02512\n",
       " 26          26  4/1/2014 4:27:00  40.6879 -74.1814  B02512\n",
       " 27          27  4/1/2014 4:38:00  40.6878 -74.1816  B02512\n",
       " 28          28  4/1/2014 4:47:00  40.7234 -73.9974  B02512\n",
       " 29          29  4/1/2014 4:49:00  40.7336 -73.9900  B02512\n",
       " ..         ...               ...      ...      ...     ...\n",
       " 69          69  4/1/2014 6:20:00  40.7599 -73.9944  B02512\n",
       " 70          70  4/1/2014 6:21:00  40.7531 -74.0039  B02512\n",
       " 71          71  4/1/2014 6:22:00  40.7791 -73.9623  B02512\n",
       " 72          72  4/1/2014 6:25:00  40.7382 -74.0033  B02512\n",
       " 73          73  4/1/2014 6:31:00  40.7391 -73.9989  B02512\n",
       " 74          74  4/1/2014 6:31:00  40.7806 -73.9820  B02512\n",
       " 75          75  4/1/2014 6:32:00  40.7322 -73.9863  B02512\n",
       " 76          76  4/1/2014 6:33:00  40.7703 -73.9660  B02512\n",
       " 77          77  4/1/2014 6:34:00  40.7221 -74.0018  B02512\n",
       " 78          78  4/1/2014 6:35:00  40.7588 -73.9895  B02512\n",
       " 79          79  4/1/2014 6:36:00  40.7677 -73.9656  B02512\n",
       " 80          80  4/1/2014 6:37:00  40.7404 -74.0076  B02512\n",
       " 81          81  4/1/2014 6:38:00  40.7679 -73.9599  B02512\n",
       " 82          82  4/1/2014 6:39:00  40.7694 -73.9852  B02512\n",
       " 83          83  4/1/2014 6:40:00  40.7858 -73.9546  B02512\n",
       " 84          84  4/1/2014 6:40:00  40.7742 -73.9491  B02512\n",
       " 85          85  4/1/2014 6:42:00  40.7703 -73.9500  B02512\n",
       " 86          86  4/1/2014 6:42:00  40.7614 -73.9997  B02512\n",
       " 87          87  4/1/2014 6:43:00  40.7930 -73.9749  B02512\n",
       " 88          88  4/1/2014 6:44:00  40.7231 -73.9442  B02512\n",
       " 89          89  4/1/2014 6:45:00  40.7874 -73.9545  B02512\n",
       " 90          90  4/1/2014 6:47:00  40.7689 -73.9812  B02512\n",
       " 91          91  4/1/2014 6:47:00  40.7789 -73.9557  B02512\n",
       " 92          92  4/1/2014 6:48:00  40.7271 -74.0054  B02512\n",
       " 93          93  4/1/2014 6:52:00  40.7877 -73.9730  B02512\n",
       " 94          94  4/1/2014 6:52:00  40.7255 -74.0092  B02512\n",
       " 95          95  4/1/2014 6:54:00  40.7653 -73.9723  B02512\n",
       " 96          96  4/1/2014 6:56:00  40.7644 -73.9769  B02512\n",
       " 97          97  4/1/2014 6:57:00  40.7726 -73.9532  B02512\n",
       " 98          98  4/1/2014 6:59:00  40.7898 -73.9661  B02512\n",
       " \n",
       " [99 rows x 5 columns],\n",
       "     Unnamed: 0         Date/Time      Lat      Lon    Base\n",
       " 0            0  5/1/2014 0:02:00  40.7521 -73.9914  B02512\n",
       " 1            1  5/1/2014 0:06:00  40.6965 -73.9715  B02512\n",
       " 2            2  5/1/2014 0:15:00  40.7464 -73.9838  B02512\n",
       " 3            3  5/1/2014 0:17:00  40.7463 -74.0011  B02512\n",
       " 4            4  5/1/2014 0:17:00  40.7594 -73.9734  B02512\n",
       " 5            5  5/1/2014 0:20:00  40.7685 -73.8625  B02512\n",
       " 6            6  5/1/2014 0:21:00  40.7637 -73.9962  B02512\n",
       " 7            7  5/1/2014 0:21:00  40.7252 -74.0023  B02512\n",
       " 8            8  5/1/2014 0:25:00  40.7607 -73.9625  B02512\n",
       " 9            9  5/1/2014 0:25:00  40.7212 -73.9879  B02512\n",
       " 10          10  5/1/2014 0:29:00  40.7255 -73.9986  B02512\n",
       " 11          11  5/1/2014 0:32:00  40.6467 -73.7901  B02512\n",
       " 12          12  5/1/2014 0:40:00  40.7613 -73.9788  B02512\n",
       " 13          13  5/1/2014 0:56:00  40.7807 -73.9497  B02512\n",
       " 14          14  5/1/2014 1:00:00  40.7585 -73.9708  B02512\n",
       " 15          15  5/1/2014 1:02:00  40.7163 -73.9895  B02512\n",
       " 16          16  5/1/2014 1:06:00  40.7265 -73.9958  B02512\n",
       " 17          17  5/1/2014 1:13:00  40.7559 -73.9867  B02512\n",
       " 18          18  5/1/2014 1:13:00  40.7671 -73.9956  B02512\n",
       " 19          19  5/1/2014 1:20:00  40.7707 -73.9944  B02512\n",
       " 20          20  5/1/2014 1:22:00  40.7607 -73.9784  B02512\n",
       " 21          21  5/1/2014 1:25:00  40.7382 -74.0096  B02512\n",
       " 22          22  5/1/2014 1:26:00  40.7590 -73.9725  B02512\n",
       " 23          23  5/1/2014 1:27:00  40.7456 -73.9915  B02512\n",
       " 24          24  5/1/2014 1:28:00  40.7285 -74.0044  B02512\n",
       " 25          25  5/1/2014 1:32:00  40.7218 -73.9921  B02512\n",
       " 26          26  5/1/2014 1:45:00  40.7440 -73.9877  B02512\n",
       " 27          27  5/1/2014 1:48:00  40.7100 -74.0091  B02512\n",
       " 28          28  5/1/2014 2:00:00  40.7412 -74.0078  B02512\n",
       " 29          29  5/1/2014 2:13:00  40.7508 -74.0056  B02512\n",
       " ..         ...               ...      ...      ...     ...\n",
       " 69          69  5/1/2014 5:17:00  40.7740 -73.9824  B02512\n",
       " 70          70  5/1/2014 5:17:00  40.7388 -74.0027  B02512\n",
       " 71          71  5/1/2014 5:18:00  40.7781 -73.9749  B02512\n",
       " 72          72  5/1/2014 5:21:00  40.7612 -73.9995  B02512\n",
       " 73          73  5/1/2014 5:23:00  40.7592 -74.0234  B02512\n",
       " 74          74  5/1/2014 5:24:00  40.8895 -73.7939  B02512\n",
       " 75          75  5/1/2014 5:27:00  40.7449 -73.9772  B02512\n",
       " 76          76  5/1/2014 5:27:00  40.7449 -73.9772  B02512\n",
       " 77          77  5/1/2014 5:29:00  40.6951 -74.1784  B02512\n",
       " 78          78  5/1/2014 5:30:00  40.7705 -73.9857  B02512\n",
       " 79          79  5/1/2014 5:34:00  40.7327 -74.0088  B02512\n",
       " 80          80  5/1/2014 5:35:00  40.7985 -73.9729  B02512\n",
       " 81          81  5/1/2014 5:36:00  40.7486 -73.9737  B02512\n",
       " 82          82  5/1/2014 5:38:00  40.7372 -74.0372  B02512\n",
       " 83          83  5/1/2014 5:38:00  40.7372 -74.0372  B02512\n",
       " 84          84  5/1/2014 5:38:00  40.7912 -73.9651  B02512\n",
       " 85          85  5/1/2014 5:39:00  40.7323 -73.9941  B02512\n",
       " 86          86  5/1/2014 5:40:00  40.7828 -73.9797  B02512\n",
       " 87          87  5/1/2014 5:40:00  40.7828 -73.9797  B02512\n",
       " 88          88  5/1/2014 5:41:00  40.7179 -73.9895  B02512\n",
       " 89          89  5/1/2014 5:46:00  40.7290 -74.0066  B02512\n",
       " 90          90  5/1/2014 5:49:00  40.8109 -74.1575  B02512\n",
       " 91          91  5/1/2014 5:49:00  40.7149 -74.0065  B02512\n",
       " 92          92  5/1/2014 5:56:00  40.7186 -74.0079  B02512\n",
       " 93          93  5/1/2014 6:03:00  40.7745 -73.9838  B02512\n",
       " 94          94  5/1/2014 6:03:00  40.7753 -73.9901  B02512\n",
       " 95          95  5/1/2014 6:07:00  40.7204 -74.0085  B02512\n",
       " 96          96  5/1/2014 6:07:00  40.7175 -74.0022  B02512\n",
       " 97          97  5/1/2014 6:07:00  40.7321 -73.9885  B02512\n",
       " 98          98  5/1/2014 6:08:00  40.7273 -73.9922  B02512\n",
       " \n",
       " [99 rows x 5 columns],\n",
       "     Unnamed: 0         Date/Time      Lat      Lon    Base\n",
       " 0            0  6/1/2014 0:00:00  40.7293 -73.9920  B02512\n",
       " 1            1  6/1/2014 0:01:00  40.7131 -74.0097  B02512\n",
       " 2            2  6/1/2014 0:04:00  40.3461 -74.6610  B02512\n",
       " 3            3  6/1/2014 0:04:00  40.7555 -73.9833  B02512\n",
       " 4            4  6/1/2014 0:07:00  40.6880 -74.1831  B02512\n",
       " 5            5  6/1/2014 0:08:00  40.7152 -73.9917  B02512\n",
       " 6            6  6/1/2014 0:08:00  40.7282 -73.9910  B02512\n",
       " 7            7  6/1/2014 0:08:00  40.3042 -73.9794  B02512\n",
       " 8            8  6/1/2014 0:09:00  40.7270 -73.9915  B02512\n",
       " 9            9  6/1/2014 0:10:00  40.7221 -73.9965  B02512\n",
       " 10          10  6/1/2014 0:11:00  40.7153 -74.0146  B02512\n",
       " 11          11  6/1/2014 0:15:00  40.6176 -74.0197  B02512\n",
       " 12          12  6/1/2014 0:16:00  40.7025 -73.9897  B02512\n",
       " 13          13  6/1/2014 0:17:00  40.7350 -74.1650  B02512\n",
       " 14          14  6/1/2014 0:17:00  40.7357 -74.0068  B02512\n",
       " 15          15  6/1/2014 0:18:00  40.6904 -73.9572  B02512\n",
       " 16          16  6/1/2014 0:19:00  40.7384 -73.9857  B02512\n",
       " 17          17  6/1/2014 0:20:00  40.7406 -74.0066  B02512\n",
       " 18          18  6/1/2014 0:21:00  40.7535 -73.9813  B02512\n",
       " 19          19  6/1/2014 0:21:00  40.7220 -73.9804  B02512\n",
       " 20          20  6/1/2014 0:23:00  40.8095 -74.1037  B02512\n",
       " 21          21  6/1/2014 0:23:00  40.7482 -73.9745  B02512\n",
       " 22          22  6/1/2014 0:30:00  40.7043 -73.9330  B02512\n",
       " 23          23  6/1/2014 0:32:00  40.7298 -73.9898  B02512\n",
       " 24          24  6/1/2014 0:32:00  40.7397 -74.0053  B02512\n",
       " 25          25  6/1/2014 0:34:00  40.7607 -74.0025  B02512\n",
       " 26          26  6/1/2014 0:37:00  40.7578 -73.9703  B02512\n",
       " 27          27  6/1/2014 0:39:00  40.7349 -73.9850  B02512\n",
       " 28          28  6/1/2014 0:39:00  40.7133 -73.9775  B02512\n",
       " 29          29  6/1/2014 0:40:00  40.7273 -73.9936  B02512\n",
       " ..         ...               ...      ...      ...     ...\n",
       " 69          69  6/1/2014 2:50:00  40.7190 -73.9888  B02512\n",
       " 70          70  6/1/2014 2:51:00  40.6564 -73.6453  B02512\n",
       " 71          71  6/1/2014 2:53:00  40.7261 -73.9918  B02512\n",
       " 72          72  6/1/2014 2:54:00  40.7191 -73.9892  B02512\n",
       " 73          73  6/1/2014 2:58:00  40.7286 -73.9954  B02512\n",
       " 74          74  6/1/2014 3:10:00  40.7615 -73.9750  B02512\n",
       " 75          75  6/1/2014 3:11:00  40.7278 -73.9991  B02512\n",
       " 76          76  6/1/2014 3:14:00  40.7503 -73.9839  B02512\n",
       " 77          77  6/1/2014 3:19:00  40.7389 -74.0081  B02512\n",
       " 78          78  6/1/2014 3:23:00  40.7750 -73.9907  B02512\n",
       " 79          79  6/1/2014 3:32:00  40.7054 -74.0072  B02512\n",
       " 80          80  6/1/2014 3:35:00  40.7303 -74.0025  B02512\n",
       " 81          81  6/1/2014 3:36:00  40.7347 -73.9924  B02512\n",
       " 82          82  6/1/2014 4:03:00  40.7224 -73.9878  B02512\n",
       " 83          83  6/1/2014 4:51:00  40.6982 -73.4620  B02512\n",
       " 84          84  6/1/2014 4:54:00  40.6449 -73.7818  B02512\n",
       " 85          85  6/1/2014 4:56:00  40.6450 -73.7820  B02512\n",
       " 86          86  6/1/2014 5:07:00  40.7699 -73.9843  B02512\n",
       " 87          87  6/1/2014 5:10:00  40.7372 -73.9967  B02512\n",
       " 88          88  6/1/2014 5:14:00  40.6448 -73.7826  B02512\n",
       " 89          89  6/1/2014 5:48:00  40.7228 -74.0019  B02512\n",
       " 90          90  6/1/2014 6:19:00  40.7360 -73.9792  B02512\n",
       " 91          91  6/1/2014 6:21:00  40.7536 -73.9915  B02512\n",
       " 92          92  6/1/2014 6:24:00  40.7615 -73.9881  B02512\n",
       " 93          93  6/1/2014 6:25:00  40.8525 -73.8281  B02512\n",
       " 94          94  6/1/2014 6:27:00  40.7554 -73.9738  B02512\n",
       " 95          95  6/1/2014 6:35:00  40.7543 -73.9817  B02512\n",
       " 96          96  6/1/2014 6:37:00  40.7751 -73.9633  B02512\n",
       " 97          97  6/1/2014 6:46:00  40.6952 -74.1784  B02512\n",
       " 98          98  6/1/2014 6:51:00  40.7621 -73.9817  B02512\n",
       " \n",
       " [99 rows x 5 columns]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list: frames\n",
    "frames = []\n",
    "\n",
    "#  Iterate over csv_files\n",
    "for csv in csv_files:\n",
    "\n",
    "    #  Read csv into a DataFrame: df\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Append df to frames\n",
    "    frames.append(df)\n",
    "\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate frames into a single DataFrame: uber\n",
    "uber = pd.concat(frames)\n",
    "\n",
    "# Print the shape of uber\n",
    "uber.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4/1/2014 0:11:00</td>\n",
       "      <td>40.7690</td>\n",
       "      <td>-73.9549</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4/1/2014 0:17:00</td>\n",
       "      <td>40.7267</td>\n",
       "      <td>-74.0345</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4/1/2014 0:21:00</td>\n",
       "      <td>40.7316</td>\n",
       "      <td>-73.9873</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4/1/2014 0:28:00</td>\n",
       "      <td>40.7588</td>\n",
       "      <td>-73.9776</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4/1/2014 0:33:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9722</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Date/Time      Lat      Lon    Base\n",
       "0           0  4/1/2014 0:11:00  40.7690 -73.9549  B02512\n",
       "1           1  4/1/2014 0:17:00  40.7267 -74.0345  B02512\n",
       "2           2  4/1/2014 0:21:00  40.7316 -73.9873  B02512\n",
       "3           3  4/1/2014 0:28:00  40.7588 -73.9776  B02512\n",
       "4           4  4/1/2014 0:33:00  40.7594 -73.9722  B02512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of uber\n",
    "uber.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now programmatically combine datasets that are broken up into many smaller parts. You'll find many datasets in the wild will be stored this way, particularly data that is collected incrementally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merge data\n",
    "## 3.1 1-to-1 data merge\n",
    "Merging data allows you to combine disparate datasets into a single dataset to do more complex analysis.\n",
    "\n",
    "Here, you'll be using survey data that contains readings that William Dyer, Frank Pabodie, and Valentina Roerich took in the late 1920 and 1930 while they were on an expedition towards Antarctica. The dataset was taken from a sqlite database from the [Software Carpentry SQL lesson](http://swcarpentry.github.io/sql-novice-survey/).\n",
    "\n",
    "Two DataFrames have been pre-loaded: `site` and `visited`. Explore them in the IPython Shell and take note of their structure and column names. Your task is to perform a 1-to-1 merge of these two DataFrames using the `'name'` column of `site` and the `'site'` column of `visited`.\n",
    "\n",
    "### Instructions:\n",
    "* Merge the `site` and `visited` DataFrames on the `'name'` column of `site` and `'site'` column of `visited`.\n",
    "* Print the merged DataFrame `o2o`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    lat    long\n",
       "0   DR-1 -49.85 -128.57\n",
       "1   DR-3 -47.15 -126.72\n",
       "2  MSK-4 -48.87 -123.40"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = pd.read_csv('_datasets/survey_site.csv')\n",
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident   site       dated\n",
       "0    619   DR-1  1927-02-08\n",
       "2    734   DR-3  1939-01-07\n",
       "6    837  MSK-4  1932-01-14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited = pd.read_csv('_datasets/survey_visited.csv')\n",
    "visited = visited.loc[[0, 2, 6]]\n",
    "visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    lat    long  ident   site       dated\n",
       "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
       "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
       "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the DataFrames: o2o\n",
    "o2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Print o2o\n",
    "o2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the 1-to-1 correspondence between the `name` column of the `site` DataFrame and the `site` column of the `visited` DataFrame. This is what made the 1-to-1 merge possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Many-to-1 data merge\n",
    "In a many-to-one (or one-to-many) merge, one of the values will be duplicated and recycled in the output. That is, one of the keys in the merge is not unique.\n",
    "\n",
    "Here, the two DataFrames `site` and `visited` have been pre-loaded once again. Note that this time, `visited` has multiple entries for the `site` column. Confirm this by exploring it in the IPython Shell.\n",
    "\n",
    "The `.merge()` method call is the same as the 1-to-1 merge from the previous exercise, but the data and output will be different.\n",
    "\n",
    "### Instructions:\n",
    "* Merge the `site` and `visited` DataFrames on the `'name'` column of `site` and `'site'` column of `visited`, exactly as you did in the previous exercise.\n",
    "* Print the merged DataFrame and then hit 'Submit Answer' to see the different output produced by this merge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    lat    long\n",
       "0   DR-1 -49.85 -128.57\n",
       "1   DR-3 -47.15 -126.72\n",
       "2  MSK-4 -48.87 -123.40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = pd.read_csv('_datasets/survey_site.csv')\n",
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>622</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>751</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>752</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>844</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1932-03-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident   site       dated\n",
       "0    619   DR-1  1927-02-08\n",
       "1    622   DR-1  1927-02-10\n",
       "2    734   DR-3  1939-01-07\n",
       "3    735   DR-3  1930-01-12\n",
       "4    751   DR-3  1930-02-26\n",
       "5    752   DR-3         NaN\n",
       "6    837  MSK-4  1932-01-14\n",
       "7    844   DR-1  1932-03-22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited = pd.read_csv('_datasets/survey_visited.csv')\n",
    "visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "# Merge the DataFrames: m2o\n",
    "m2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Print m2o\n",
    "print(m2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `site` data is duplicated during this many-to-1 merge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Many-to-many data merge\n",
    "The final merging scenario occurs when both DataFrames do not have unique keys for a merge. What happens here is that for each duplicated key, every pairwise combination will be created.\n",
    "\n",
    "Two example DataFrames that share common key values have been pre-loaded: `df1` and `df2`. Another DataFrame `df3`, which is the result of `df1` merged with `df2`, has been pre-loaded. All three DataFrames have been printed - look at the output and notice how pairwise combinations have been created. This example is to help you develop your intuition for many-to-many merges.\n",
    "\n",
    "Here, you'll work with the `site` and `visited` DataFrames from before, and a new `survey` DataFrame. Your task is to merge `site` and `visited` as you did in the earlier exercises. You will then merge this merged DataFrame with `survey`.\n",
    "\n",
    "Begin by exploring the `site`, `visited`, and `survey` DataFrames in the IPython Shell.\n",
    "\n",
    "### Instructions:\n",
    "* Merge the `site` and `visited` DataFrames on the `'name'` column of `site` and `'site'` column of `visited`, exactly as you did in the previous two exercises. Save the result as `m2m`.\n",
    "* Merge the `m2m` and `survey` DataFrames on the `'ident'` column of `m2m` and `'taken'` column of `survey`.\n",
    "* Hit 'Submit Answer' to print the first 20 lines of the merged DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    lat    long\n",
       "0   DR-1 -49.85 -128.57\n",
       "1   DR-3 -47.15 -126.72\n",
       "2  MSK-4 -48.87 -123.40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = pd.read_csv('_datasets/survey_site.csv')\n",
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>622</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>751</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>752</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>844</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1932-03-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident   site       dated\n",
       "0    619   DR-1  1927-02-08\n",
       "1    622   DR-1  1927-02-10\n",
       "2    734   DR-3  1939-01-07\n",
       "3    735   DR-3  1930-01-12\n",
       "4    751   DR-3  1930-02-26\n",
       "5    752   DR-3         NaN\n",
       "6    837  MSK-4  1932-01-14\n",
       "7    844   DR-1  1932-03-22"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited = pd.read_csv('_datasets/survey_visited.csv')\n",
    "visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taken</th>\n",
       "      <th>person</th>\n",
       "      <th>quant</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>dyer</td>\n",
       "      <td>rad</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619</td>\n",
       "      <td>dyer</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>622</td>\n",
       "      <td>dyer</td>\n",
       "      <td>rad</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622</td>\n",
       "      <td>dyer</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>734</td>\n",
       "      <td>pb</td>\n",
       "      <td>rad</td>\n",
       "      <td>8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>734</td>\n",
       "      <td>lake</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>734</td>\n",
       "      <td>pb</td>\n",
       "      <td>temp</td>\n",
       "      <td>-21.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>735</td>\n",
       "      <td>pb</td>\n",
       "      <td>rad</td>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>temp</td>\n",
       "      <td>-26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>751</td>\n",
       "      <td>pb</td>\n",
       "      <td>rad</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>751</td>\n",
       "      <td>pb</td>\n",
       "      <td>temp</td>\n",
       "      <td>-18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>751</td>\n",
       "      <td>lake</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>752</td>\n",
       "      <td>lake</td>\n",
       "      <td>rad</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>752</td>\n",
       "      <td>lake</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>752</td>\n",
       "      <td>lake</td>\n",
       "      <td>temp</td>\n",
       "      <td>-16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>752</td>\n",
       "      <td>roe</td>\n",
       "      <td>sal</td>\n",
       "      <td>41.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>837</td>\n",
       "      <td>lake</td>\n",
       "      <td>rad</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>837</td>\n",
       "      <td>lake</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>837</td>\n",
       "      <td>roe</td>\n",
       "      <td>sal</td>\n",
       "      <td>22.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>844</td>\n",
       "      <td>roe</td>\n",
       "      <td>rad</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    taken person quant  reading\n",
       "0     619   dyer   rad     9.82\n",
       "1     619   dyer   sal     0.13\n",
       "2     622   dyer   rad     7.80\n",
       "3     622   dyer   sal     0.09\n",
       "4     734     pb   rad     8.41\n",
       "5     734   lake   sal     0.05\n",
       "6     734     pb  temp   -21.50\n",
       "7     735     pb   rad     7.22\n",
       "8     735    NaN   sal     0.06\n",
       "9     735    NaN  temp   -26.00\n",
       "10    751     pb   rad     4.35\n",
       "11    751     pb  temp   -18.50\n",
       "12    751   lake   sal     0.10\n",
       "13    752   lake   rad     2.19\n",
       "14    752   lake   sal     0.09\n",
       "15    752   lake  temp   -16.00\n",
       "16    752    roe   sal    41.60\n",
       "17    837   lake   rad     1.46\n",
       "18    837   lake   sal     0.21\n",
       "19    837    roe   sal    22.50\n",
       "20    844    roe   rad    11.25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey = pd.read_csv('_datasets/survey_survey.csv')\n",
    "survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name    lat    long  ident   site       dated  taken person quant  \\\n",
      "0    DR-1 -49.85 -128.57    619   DR-1  1927-02-08    619   dyer   rad   \n",
      "1    DR-1 -49.85 -128.57    619   DR-1  1927-02-08    619   dyer   sal   \n",
      "2    DR-1 -49.85 -128.57    622   DR-1  1927-02-10    622   dyer   rad   \n",
      "3    DR-1 -49.85 -128.57    622   DR-1  1927-02-10    622   dyer   sal   \n",
      "4    DR-1 -49.85 -128.57    844   DR-1  1932-03-22    844    roe   rad   \n",
      "5    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734     pb   rad   \n",
      "6    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734   lake   sal   \n",
      "7    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734     pb  temp   \n",
      "8    DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735     pb   rad   \n",
      "9    DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735    NaN   sal   \n",
      "10   DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735    NaN  temp   \n",
      "11   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751     pb   rad   \n",
      "12   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751     pb  temp   \n",
      "13   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751   lake   sal   \n",
      "14   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake   rad   \n",
      "15   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake   sal   \n",
      "16   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake  temp   \n",
      "17   DR-3 -47.15 -126.72    752   DR-3         NaN    752    roe   sal   \n",
      "18  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14    837   lake   rad   \n",
      "19  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14    837   lake   sal   \n",
      "\n",
      "    reading  \n",
      "0      9.82  \n",
      "1      0.13  \n",
      "2      7.80  \n",
      "3      0.09  \n",
      "4     11.25  \n",
      "5      8.41  \n",
      "6      0.05  \n",
      "7    -21.50  \n",
      "8      7.22  \n",
      "9      0.06  \n",
      "10   -26.00  \n",
      "11     4.35  \n",
      "12   -18.50  \n",
      "13     0.10  \n",
      "14     2.19  \n",
      "15     0.09  \n",
      "16   -16.00  \n",
      "17    41.60  \n",
      "18     1.46  \n",
      "19     0.21  \n"
     ]
    }
   ],
   "source": [
    "# Merge site and visited: m2m\n",
    "m2m = pd.merge(left=site, right=visited, left_on=\"name\", right_on='site')\n",
    "\n",
    "# Merge m2m and survey: m2m\n",
    "m2m = pd.merge(left=m2m, right=survey, left_on='ident', right_on='taken')\n",
    "\n",
    "# Print the first 20 lines of m2m\n",
    "print(m2m.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the keys are duplicated in this many-to-many merge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
